# Metrics & Observability Plan

This document defines the metrics, logging, and tracing strategy for the Cloudflare Workers AI multi-tenant platform. Our goal is to have a system that is transparent, easy to debug, and provides clear signals on performance, reliability, and cost.

## 1. Guiding Principles

- **Observability is a Feature:** We will treat observability as a first-class citizen, not an afterthought.
- **Structured Logging:** All logs will be in a structured JSON format to enable easy parsing and querying.
- **The Three Pillars:** We will collect metrics, logs, and traces to provide a complete picture of the system's health.

## 2. Logging

### 2.1. Structured Log Schema

All logs will adhere to the following JSON schema:

```json
{
  "timestamp": "ISO_8601_TIMESTAMP",
  "level": "info|warn|error",
  "message": "A human-readable message",
  "service": "worker-api|ingest-worker",
  "tenant_id": "com.rainbowsmokeofficial|com-mrrainbowsmoke",
  "request_id": "UUID",
  "route": "/chat|/search|/ingest",
  "latency_ms": 123,
  "status_code": 200,
  "error": {
    "message": "Error message if any",
    "stack": "Stack trace if any"
  },
  "metadata": {
    "key": "value"
  }
}
```

### 2.2. Log Redaction

To prevent leaking sensitive data, we will automatically redact the following:

- `Authorization` and `Cookie` headers.
- Raw user prompts and AI responses (unless explicitly enabled for debugging).
- Personally Identifiable Information (PII).

## 3. Metrics

We will collect the following key metrics, tagged by `tenant_id`, `route`, and `service`.

### 3.1. API Metrics

- **`requests_total` (Counter):** Total number of requests.
- **`errors_total` (Counter):** Total number of errors.
- **`latency_ms` (Histogram):** Distribution of request latency.
- **`rate_limited_total` (Counter):** Number of requests that were rate-limited.

### 3.2. AI & Model Metrics

- **`ai_requests_total` (Counter):** Total number of requests to AI models.
- **`ai_errors_total` (Counter):** Total number of errors from AI models.
- **`ai_latency_ms` (Histogram):** Latency of AI model responses.
- **`ai_tokens_input` (Counter):** Number of input tokens processed by AI models.
- **`ai_tokens_output` (Counter):** Number of output tokens generated by AI models.

### 3.3. Storage Metrics

- **`vectorize_queries_total` (Counter):** Total number of queries to Vectorize.
- **`vectorize_latency_ms` (Histogram):** Latency of Vectorize queries.
- **`kv_reads_total` (Counter):** Total number of reads from KV.
- **`kv_writes_total` (Counter):** Total number of writes to KV.
- **`do_requests_total` (Counter):** Total number of requests to Durable Objects.

### 3.4. RAG Metrics

- **`rag_retrieval_count` (Histogram):** Number of documents retrieved per query.
- **`rag_cache_hit_rate` (Gauge):** The percentage of RAG queries served from the cache.

## 4. Tracing

While Cloudflare Workers has some limitations on traditional APM tracing, we will implement a lightweight tracing system using a unique `request_id`.

- The `request_id` will be generated at the edge and passed to all downstream services.
- We will log the `request_id` at each step of the request lifecycle, allowing us to reconstruct the flow of a request through the system.

## 5. Dashboards & Alerts

We will create a set of dashboards and alerts to monitor the health of the system.

### 5.1. Dashboards

- **Overview Dashboard:** High-level overview of the system's health, including key metrics like requests, errors, and latency.
- **Tenant Dashboard:** A drill-down view of metrics per tenant.
- **AI Dashboard:** Metrics related to AI model performance and cost.
- **Storage Dashboard:** Metrics for Vectorize, KV, and Durable Objects.

### 5.2. Alerts

- **High Error Rate:** Alert when the error rate exceeds a certain threshold.
- **High Latency:** Alert when the p95 latency exceeds a certain threshold.
- **High AI Costs:** Alert when the number of AI tokens processed exceeds a budget.
- **Storage Errors:** Alert on errors from Vectorize, KV, or Durable Objects.
